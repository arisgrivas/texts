Vol.:(0123456789)
Public Choice (2020) 185:253–279 https://doi.org/10.1007/s11127-019-00713-4
13
A developmental approach to historical causal inference
David A. Bateman1 · Dawn Langan Teele2
Received: 17 August 2019 / Accepted: 26 August 2019 / Published online: 3 September 2019 © Springer Science+Business Media, LLC, part of Springer Nature 2019
Abstract
Empirical historical research typically falls into one of three categories: the study of major historical events; the use of “history as data” to test general theories; and the study of the legacies of historical processes. We argue that because of data sparsity and dynamically unfolding processes, the study of major historical events is less well suited to design-based inference than other types of historical research. Drawing examples from our own work, we propose a set of research procedures for designing causally oriented work, and argue that the construction of a “timeline of relevant counterfactual nodes” can facilitate the organization of a research project investigating complex historical processes. The researcher can focus on relevant counterfactual moments as potential episodes of change using either statistical or qualitative techniques as appropriate, moving forward through the timeline and updating their beliefs about a hypothesized cause’s importance across the process.
Keywords Causal inference · American political development · Historical institutionalism
JEL Classification D72 · C18 · N41
1 Introduction
While both description and interpretation are key elements of social science research, the goal to which many of us aspire is the ability to make and substantiate empirically causal explanations for complex social phenomena. We want to know what has happened, what it means, what its consequences were or will be; but, perhaps above all, we want to know why it’s happened. That is, to put it mildly, a tricky business, and debates about what causation is, and how best to go about doing causal inference, have been central to social science since its emergence as a distinctive field of study.
* David A. Bateman dab465@cornell.edu
Dawn Langan Teele teele@sas.upenn.edu
1 Department of Government, Cornell University, 218 White Hall, Ithaca, NY 14853, USA
2 Political Science Department, University of Pennsylvania, 434 Ronald O. Perelman Center for Political Science and Economics, Philadelphia, PA 19104, USA


254 Public Choice (2020) 185:253–279
13
With the rise of a more formalized counterfactual approach to causal inference—the potential outcomes framework (Rubin 1974; Holland 1986; Neyman 1990)—there has been a renewed appreciation for, and use of, experimental and so-called quasi-experimental methods across the discipline (Dunning 2012; Diamond and Robinson 2010; Morgan and Winship 2007; Pearl 1995). The advent of the potential outcomes framework has helped drive the “historical turn” in comparative politics and fostered broader appreciation for history in the study of American politics, reaching well-beyond the confines of American
political development (APD) as a distinct scholarly community.1 But design-based inference has yet to produce a single standard for conducting research into the present or the past (Sekhon and Titiunik 2012; Heckman and Urzúa 2010; Deaton 2010; see also Keele 2015; Imbens 2010). The proliferation of design-based inference in historical research, while rapid, has been uneven, both because it is more closely aligned with narratives of “single” causation and because of considerable variation across historical research areas in the quantity and quality of descriptive data as well as the historiographical debates necessary for its contextualized interpretation. We argue that the characteristics of much historical research—a concern with particular cases whose causes unfolded dynamically and for which we often have very limited datapresent inferential challenges that cannot be addressed mechanically within a potentialoutcomes framework. We suggest instead that a more pressing need for establishing causal inference is a set of procedures for guiding historical research. The particular procedures we offer here are intended to facilitate recognizing dynamic causal processes where and when they occur, thereby helping researchers design strategies for evaluating logically and empirically how well different causal hypotheses hold up across the totality of a developing historical process. Historical social scientific questions that lend themselves to empirically grounded causal analyses fall into different categories, three of which are particularly common in political science and cognate fields. The first of those categories are questions about “legacies”, when scholars seek to understand the impact of a historical phenomenon on other political outcomes. Sometimes the effects scholars look for are short-term, but sometimes scholars hope to understand contemporary phenomena in light of long-term cultural and economic
consequences of specific historical interventions.2 The second category might be described as “history as data” type questions, in which the researcher approaches historical episodes as data points that can be leveraged to analyze more general theories of politics. The third category, and the primary focus of this paper, are questions about particular “historical events”, in which scholars attempt to establish varyingly comprehensive explanations for the timing and nature of major political transformations. As we argue in Sect. 3, the strictures of most design-based approaches do not lend themselves equally well to answering all three types of questions. The historical legacies branch is perhaps especially compatible with a potential outcomes or design-based inference framework, in part because temporal distance plausibly can be leveraged for purposes of causal identification. The second type of question is less concerned with history as history than with history-as-data, treating the past as a repository of observations that can be leveraged for either increasing statistical power or providing variation across key variables
1 On the historical turn, see Capoccia and Ziblatt (2010); on the relationship between American political development and historical approaches to comparative politics, see Morgan (2016).
2 We thank Scott Abramson for sharing a related categorization at the historical political economy working group meeting, APSA 2017.


255
Public Choice (2020) 185:253–279
13
or parameters of interest. Researchers operating in both the historical legacies and the history-as-data genres often can use coarser indicators from the past, paired with more finely grained and multifaceted data from the contemporary era. Because they are less interested in understanding the distinctive features of a specific historical moment or event, researchers working in those modes can even supplement historical data with newly constructed data that they can tailor to better satisfy the assumptions of design-based inference. The third type of historical research, on major historical events, arguably is one of the most common types of question asked by scholars working in American political development, and we suggest that it also is the most difficult to study in a design-based framework. Questions about why a particular event occurred are by no means empirically intractable, nor will research into them be uninformed by more generalizable theories. But the very nature of the question makes data limitations more severe than in “history-as-data” type questions, while the dynamic nature of many of the events means that rather than leveraging temporality for purposes of identification, we must integrate time’s particular dynamics into our explanations. That is, if the event we seek to explain was not a single interruption in political and social life, but one that unfolded dynamically over time, then modeling the causal process requires close attention to the possibility for co-determination in the values of important covariates. Our paper details some of the common challenges that confront researchers looking to make causal arguments in the third of the foregoing types of questions, that is, the explanation of major historical events. Those issues are close to our hearts, as they are ones that we confronted in our own investigations into why the right to vote was extended to African American men during the nineteenth century, why different countries adopted women’s suffrage at different junctures, and why Congress failed to pass robust voting rights legislation in the late nineteenth century (Teele 2018a, b; Bateman 2018, 2019; Bateman et al. 2018). As the two of use discovered, answering such questions often is less about identifying a causal effect for a single variable than about evaluating the relative contributions of different theorized causes whose importance and effects might develop dynamically over an extended period of time. Even when the framework explicitly is comparative, the resulting research often veers toward being more case-centered than theory-centered, i.e., it is focused on providing a fuller accounting of a few specific events or processes rather than establishing empirically a generalized theory of how different variables or processes relate
to each other across cases (Rohlfing 2012).3 And because we are interested in explaining a particular case or set of cases, we cannot always assume that observing and recording data from similar phenomena in the future would provide much additional leverage for explaining the past, even if we make the often-ahistorical assumption that a causal relationship established for one period applies with equal force in another (Haydu 1998). What is more, when data repositories exist or could be recovered, they are almost certain to have been generated and collected with different ends in mind; even with a deep dive into the archives and original data collection methods, the empirical foundations of the analyses generally will be sparser and more conceptually distant than we would desire.
3 As Kathleen Thelen (1999, p. 371) and others have argued, a key difference between historical institutionalism (HI) and rational choice institutionalism (RCI) lies in how hypotheses are formulated. Whereas HI proceeds from an interest in historical empirical puzzles, RCI is more concerned with how institutions deviate from deductively derived theories of politics.


256 Public Choice (2020) 185:253–279
13
We begin with short vignettes describing the research questions, processes, and outcomes from our recent work on franchise expansion to black men and women. The vignettes help to ground three claims we advance in the remainder of the paper. The first claim simply is that prominent ways of analyzing historical events—fixed effects regression frameworks, historical event analysis, but also many of the logical tests researchers apply in evaluating qualitative process-tracing studies—are likely to produce biased estimates of hypothesized causal factors if they fail to model their developmental and dynamic character across a particular period. That will be true whether our objective is estimating a causal effect across multiple cases or establishing the validity or weight of a causal hypothesis in a single case. As a result, studying particular historical events should, as a matter of general practice, integrate some features of process-tracing, even if just to establish the appropriateness of a design-based inferential model. Good statistical work on historical events, like good qualitative work, will require scholars to be close to their cases, regardless of the epistemological grounding of their approach (Goertz and Mahoney 2012;
Kocher and Monteiro 2016).4 The second claim follows from the first, and is the foundation for the positive contribution we hope to make with this article. Because of the difficulties of studying dynamic processes, especially given the data sparsity and unevenness ubiquitous to much historical research, we do not expect to find a mechanical solution that can be applied generally. Instead, those of us interested in making causal inferences about historical events should focus on developing a set of research procedures that can be used to guide research design and facilitate causal inference across a historically unfolding process. In particular, we propose that scholars center their data collection and analysis around a timeline of “relevant” counterfactual moments—temporally defined instances in which an outcome actually was possible, but did not occur (Simon 2014). Researchers then can study those moments using either statistical or qualitative techniques as appropriate, moving forward through the timeline and updating their beliefs about a hypothesized cause’s importance across the process. Our third claim is simply that as a discipline our valuation of historical research should be assessed relative to the prior state of knowledge. Statistical estimation of a causal effect is not the only means by which causal inference can be undertaken—given sufficiently specified theory, description itself arguably is a powerful tool for establishing causality (Falleti 2016)—and in the study of historical events it often will be impossible within a single unified framework. In a terrain with deep prior knowledge and rich data sources, scholars may be able to make advances using quantitative concepts of identification; in sparser fields, by contrast, the descriptive documentation of a process, including the recovery and analysis of possible counterfactual moments, is itself an important contribution to knowledge and causal inference (Kreuzer 2019). We suggest in the conclusion that our three claims amount to taking a developmental perspective on the conduct and evaluation of historical research, one that is sensitive to temporality and sequencing, that facilitates causal inference across an unfolding process, and does not prioritize estimation of a single causal effect over other more cumulative contributions to knowledge.
4 We address the relevance of our approach for contemporary research in Sect. 3.


257
Public Choice (2020) 185:253–279
13
2 Questions, processes and outcomes
In the process of conducting our separate research into black suffrage and the antecedents of women’s enfranchisement, we began to understand that our first intuitions about how to study the passage of suffrage reforms failed to appreciate or model adequately the sequencing of the historical process that led to reform. Moreover, while we both tackled problems of compiling and measuring scarce data for what we eventually came to see as dynamic processes, we confronted very different existing research infrastructures in terms of the prior knowledge and data sources we had readily available. That had major implications for the allocations of our time in the research process, and for the resulting products of our work. We describe the challenges we faced individually in the sections that follow.
2.1 Bateman: sparse data and the tradeoffs of research
My plan for a study of African American voting rights, which eventually developed into the book Disenfranchising Democracy (Bateman 2018), began with a rough timeline of suffrage reform across American history. The basic sequence I was interested in is shown in Fig. 1, which shows the dates at which states or territories either newly disenfranchised or enfranchised African Americans, as well as the admission of new states with disenfranchising or enfranchising provisions. The initial research strategy was to compare the politics of black voting rights across three periods, beginning with the first wave of disenfranchisement that ended in the mid-1830s, then turning to the mass enfranchisements of 1866–1870, and concluding with the mass disenfranchisements of the late nineteenth and early twentieth centuries. I anticipated that the bulk of my research time would be spent studying the second and third periods. That study never happened. Instead, I started digging around in the antebellum era and never quite dug myself all the way out. The reason had much to do with the infrastructure of available knowledge and data, and the complications that arose as I tried to expand on them. What I found was that not only was relatively little written about the initial period of disenfranchisement, and almost no data on its occurrence, but that the period I was planning on skipping over entirely—from approximately 1835–1865, where the middle panel of Fig. 1 shows nothing much happening—had in fact witnessed considerable political activity, including speeches, writing, legislative voting, public referendums, and petitioning on the issue of black suffrage. An issue that exploded onto the political agenda in 1867, and remained at a fever pitch for years afterwards, already had been a feature of political debate and the subject of intense legislative fights at the state level for at least two-and-ahalf decades. Certainly, black suffrage before the Civil War was a different thing than it would become afterwards: enfranchising the relatively small free African American population in any given state would not have been the same as expanding the right to vote to millions of newly freed men in the South. But many of the arguments being deployed in 1867 for and against black suffrage already had been made; numerous states already had experienced intense political organizing on that issue; and northern state legislatures and constitutional conventions saw majorities or near majorities of Republican legislators vote in its favor between 1856 and 1859. It even seems likely that in at least two northern states—Wisconsin and New York—a majority of Republican voters had voted in favor of equal voting rights for men by 1859 (Bateman 2019; Field 1982).


258 Public Choice (2020) 185:253–279
13
It is not that no one knew of that earlier experience. Most accounts of black enfranchisement post-Civil War, for instance, acknowledged the importance of local organizing, and some gestured toward a longer process of contestation (Wang 1997). But historians of the antebellum era had not mapped out systematically how black enfranchisement was put on the political agenda of most northern states, connected to the antislavery cause in rhetoric and public opinion, and anchored as the radical position of
Delaware
Kentucky
Maryland
Ohio NewJersey
Indiana,Mississippi
Louisiana
Missouri
Connecticut
Michigan
NewYork
RhodeIsland
Tennessee
NorthCarolina
Pennsylvania
1790 1800 1810 1820 1830 1840
RhodeIsland
Wisconsin
Nebraska,Territories
ReconstructionStates,Iowa
Minnesota
15thAmendment
1840 1845 1850 1855 1860 1865 1870 1875
Florida,Tennessee
Mississippi
Louisiana
SouthCarolina
Arkansas
NorthCarolina
Alabama
Virginia
Texas
Georgia
Oklahoma
1875 1880 1885 1890 1895 1900 1905 1910 1915 1920
Black disfranchisement Black enfranchisement New state − disenfranchising New state − enfranchising
Timeline of disenfranchisement and re−enfranchisement
Fig. 1 Timeline of disenfranchisement and re-enfranchisement


259
Public Choice (2020) 185:253–279
13
the Republican Party well before the Civil War. Lacking that historical infrastructure, scholars of black enfranchisement in general acknowledged that the issue had come up before the Civil War, but had stopped there, either not fully appreciating the breadth and duration of activism on the issue or taking it as a background condition that effectively could be ignored in studying the debates over black suffrage post-1865. The problem, from a causal analysis perspective, was that while neglect certainly did not invalidate dominant accounts of post-War black enfranchisement—that it was motivated by the strategic desire of the Republican Party to remain in power (Valelly 2004)—it perhaps meant that we were overestimating the significance of party politics relative to the other accounts that stressed a more programmatic and social movementbased motivation (e.g., Cox and Cox 1967), rooted in both the extraordinary organizing of newly free persons described by Valelly, but also the older antislavery societies and conventions of free persons of color. If large factions of the Republican Party had been willing to support black suffrage as early as 1860, then the motivations and strategic choices made by party leaders and issue entrepreneurs in 1867 took on a different cast. Appeals to party politics and arguments stressing the threat of a revitalized Democratic Party certainly were important; but local activism, as it unfolded over the long term, meant that a sympathetic and supportive cadre of Republicans on which to build already was in place. Instead of having to build support among a majority of their own party, party leaders had to focus on the pivotal Republicans, often from border states or states where abolitionists had not been organized effectively. In short, I had come to believe that the earlier activism dynamically had altered the state of public opinion and the relative importance of electoral calculations to the final outcome: instead of studying them as a succession of independent cases, they had to be considered in a temporal sequence. However, little guidance is available on how to study a dynamic causal process in a potential-outcomes framework, and that which is at one’s disposal (Blackwell 2013) requires data at a level of temporal and spatial granularity that simply did not exist. Moreover, while I already had decided on a mixed-methods approach, pairing qualitative process-tracing with statistical evaluations of legislator voting, the data infrastructure for voting in state legislatures and constitutional conventions was next to non-existent for that period. Lacking an existing data repository for identifying when and where the issue was debated and voted on, the time and resources allocated to constructing such a dataset took priority over recovering conditioning variables necessary to construct a fully specified model blocking out all “back-door” pathways to black suffrage (Morgan and Winship 2007; Pearl 1995). For that reason, the claims made in my study of black suffrage politics as it developed in the antebellum era (Bateman 2019) largely have remained descriptive, and the gestures I make toward a more causal story come primarily from a qualitative tracing of the process by which black suffrage was put on the agenda and voted on across different states, supplemented where possible by descriptive statistical and quantitative data. Recognizing the enfranchisement of African American men in the nineteenth century as a dynamic process makes it difficult to conceive of how we might study it as an event in a causal inference framework, and any single statistical estimate of the different potential causes at the moment of its “final” occurrence will be biased unless it integrates the longer process. Studying the relationship of different variables at different times, and tracing their sequential unfolding, however, will leave us without a cleanly identified estimate of causal effect. In such a case, at least for the moment, descriptive statistical claims with causally oriented qualitative process-tracing might be the best that can be made.


260 Public Choice (2020) 185:253–279
13
2.2 Teele: rich data terrain meant expanding measures on the right‐hand side
In the beginning of my research for Forging the Franchise: The Political Origins of the Women’s Vote (Teele 2018a), I discovered a mountain of information on the women’s suffrage campaign, particularly in the United States, that served as a jumping off point for subsequent statistical research. The suffragists themselves were keenly aware of the historymaking they were involved in, and kept detailed records—published in six volumes as the History of Woman Suffrage—which they marched over to the Library of Congress shortly after the Nineteenth Amendment was ratified in 1920. The often-repeated quote is that to win women the vote it took
fifty-six campaigns of referenda to male voters; 480 campaigns to urge Legislatures to submit suffrage amendments to voters; 47 campaigns to induce State constitutional conventions to write woman suffrage into State constitutions; 277 campaigns to persuade State party conventions to include woman suffrage planks; 30 campaigns to urge presidential party conventions to adopt woman suffrage planks in party platforms, and 19 campaigns with 19 successive Congresses. (Catt and Shuler 1923, p. 107)
Each of those campaigns was recorded to a greater or lesser extent by the suffragists in the History of Woman Suffrage. When I first “discovered” the volumes for myself, my intuition was to try to skim them all and then code the whole thing. Instead, I familiarized myself with the secondary literature on women’s suffrage, and realized that much more data-informed work had been done on this topic than I had imagined previously. Since we already knew the dates in which different states had allowed women “full” suffrage on the same terms as men, many scholars invested time in measuring causal variables. Banaszak (1996) plumbed the minutes of the National Woman Suffrage Association and came up with a measure (albeit imperfect) of membership in the NAWSA’s statelevel branches over time. (We still lack local branch membership information, however). McCammon et al. (2001) already had examined the types of tactics that suffragists used
over time, e.g., direct-action tactics like protests, or writing newspaper editorials.5 Her team also considered the types of arguments suffragists made, whether appealing to the political expedience of enfranchising women or to justice-based arguments. The findings that those scholars presented convinced me that the movement’s strategy mattered, but I hoped to build on that work on two fronts: first I wanted to know more about the larger history within states—why, for example, some states like Massachusetts considered the issue repeatedly in legislative proceedings, but was extremely resistant to adoption—and I wanted to know more about the political catalysts or hindrances. My qualitative research into the suffrage politics in the United Kingdom (Teele 2014) convinced me that ruptures in political competition—whether you want to call it realignment or an increase in competition—led to entrepreneurial thinking on the parts of politicians. Although multiple legislatures in the whole of Great Britain had some jurisdiction over suffrage (e.g., the Tynwald in the Isle of Man), my main concern was why Westminster’s parliamentarians had resisted suffrage, even when the Liberals came to power in 1906, but ultimately enfranchised (most) women in 1918. I examined the debates and
5 McCammon et al. (2001), for example, found that expedience-type arguments were more successful and may have accounted for early western extensions. Although during the course of my work I had asked McCammon to share her data, she was not able or willing to do so.


261
Public Choice (2020) 185:253–279
13
internal correspondence between legislators and suffragists in the period from 1910 to 1918 and constructed a timeline. The other moments of potential reform were obvious: they coincided with dates on which private member bills for suffrage were proposed, debated, or voted on in each period. I studied the voting histories of the various parties (and the factions within them) and came to the conclusion that the changing political conditions that emerged in the wake of the First World War were salient for suffrage only insofar as they strengthened competition, not because they changed anyone’s minds (earlier bills with the same group of legislators already had garnered majorities). The political holdouts continued to be a group of conservatives afraid of the leftism among women (so they agreed only to let older and wealthier women vote) and the leader of the Liberal Party also feared the leftward direction of women’s votes. The point is, that I came to the US case with a “prior” belief about the conditions under which suffrage would emerge and wanted to use the larger amount of variation across the US states as a plausibility probe or “hoop test” for examining my ideas. The problem was that the fine-grained knowledge I had of the sequence of reform in the United Kingdom was not going to be possible to acquire for 45–48 odd states. So, I instead read as much of the historiography of the US suffrage movement as I could, and I also delved into the literature on American political development. Reading those works, I began to form an intuition that competition probably also was instructive for the passage of suffrage in the United States, but that it operated in slightly different ways related not only to which party was in power, but how long it had held control, whether the power was projected across multiple levels of state government, and how large a majority it had. The issue of political machines also arose. Many suffragists felt that the machines were against women’s enfranchisement because of the moral project that was a part of the suffrage movement. If women wanted to clean up dirty corrupt politics, the machines would be an obvious adversary. My first attempt at studying state-level enfranchisement quantitatively was then to try to measure competition in a more sophisticated way, and to replicate others’ studies of the final reform. I spent the year 2011 working on measuring political competition and I spent the summer thereafter working with a research assistant to collect information on political machines at the city level throughout the Gilded Age. My first attempt at studying state-level enfranchisement quantitatively thus was to replicate others’ studies of the final reform, but to improve on the causal variables related to political competition. That was unsatisfying because the final date of enfranchisement often was not related to legislative passage within a state, but instead to a successful referendum. My intuition was that examining bill passage in the United States, as I did in the United Kingdom, would allow for more statistical leverage than previous studies. But at some point in 2011, I discovered a gold mine: King et al. (2005) research into the step-bystep legislative process that the suffragists had to navigate. That team of researchers had, amazingly, collected a database that listed (or approached) every single bill introduced in every state legislature related to women’s suffrage throughout the entire campaign. The authors’ spreadsheet contained 1124 rows, 610 of which pertained to full suffrage rights, 562 of which were unique (see Table 1). Gaining access to their data felt less like standing on shoulders than soaring through the air. Like earlier scholars, their own research with those data had focused more on the social movement side (using some of McCammon’s data in their analyses) and less on the political variables. Thus, room definitely was available for contributing to the conversation. The fact that data related to the historical sequencing of women’s suffrage in the United States already existed was a huge boon to my project. To be sure, I had to do a lot of work to understand what was there (as detailed in the long appendix in Teele 2018b), and


262 Public Choice (2020) 185:253–279
13
Table 1 All unique attempts at full women’s suffrage bills in the US States, 1850–1920
State House bills Senate bills Ballot measures Type Passed
Introduced Voted Passed Introduced Voted Passed Initiative Legislative Constutional
Alabama 1 1 0 1 1 0 No
Arkansas 5 3 2 4 3 3 1 C No
Arizona 11 10 7 12 6 1 1 I Yes
California 13 5 2 20 9 5 2 LL Yes
Colorado 6 4 2 4 3 3 2 LL Yes
Connecticut 8 4 2 2 1 1 No
Delaware 4 3 0 5 3 0 No
Florida 7 3 0 4 2 2 No
Georgia 8 0 0 3 0 0 No
Iowa 27 16 12 27 17 10 1 L No
Idaho 5 4 1 2 1 1 1 L Yes
Illinois 3 1 0 3 1 0 No
Indiana 12 5 4 10 6 3 No
Kansas 13 5 4 9 6 3 3 LLL Yes
Kentucky 1 1 0 2 1 0 No
Louisiana 4 4 2 4 2 1 1 L No
Massachusetts 23 8 2 9 4 4 1 L No
Maryland 5 0 0 3 1 1 No
Maine 8 6 2 5 5 2 1 L No
Michigan 14 9 4 7 6 3 4 LLLL Yes
Minnesota 8 3 3 9 3 0 No
Missouri 12 1 0 3 0 0 1 I No
Mississippi 3 3 2 5 4 2 No
Montana 10 5 2 3 1 1 1 L Yes
North Carolina 2 0 0 2 0 0 No
North Dakota 14 10 6 12 12 9 1 L No


263
Public Choice (2020) 185:253–279
13
Bills attempting to pass full women’s suffrage at the state level, 1850–1920. The table lists the total number of bills introduced, voted on, and passed in the respective state
houses and state senates, as well as the total number of ballot measures, be they ballot initiatives, legislative referendum, or referendum on constitutional conventions that con
tained language for women’s suffrage. Source: Teele’s calculations from Cornwall’s Suffrage Database
Table 1 (continued)
State House bills Senate bills Ballot measures Type Passed
Introduced Voted Passed Introduced Voted Passed Initiative Legislative Constutional
Nebraska 7 4 2 7 3 1 1 1 1 ILC No
New Hampshire 1 0 0 4 4 3 1 C No
New Jersey 6 4 3 2 0 0 1 L No
New Mexico 1 0 0 12 9 6 No
Nevada 10 10 5 14 7 6 1 L Yes
New York 28 12 5 6 2 1 2 LL Yes
Ohio 7 3 1 8 1 1 1 1 IC No
Oklahoma 10 4 4 8 7 4 1 1 IL Yes
Oregon 10 8 6 9 3 3 4 2 IIIILL Yes
Pennsylvania 7 5 3 5 3 3 1 L No
Rhode Island 6 5 3 4 3 0 1 L No
South Carolina 6 2 0 15 13 10 No
South Dakota 14 12 8 2 1 1 6 LLLLLL Yes
Tennessee 1 1 1 3 1 1 No
Texas 10 2 1 1 1 1 1 L No
Utah 1 1 1 1 0 0 1 C Yes
Virginia 3 3 0 3 3 1 No
Vermont 1 1 1 7 6 5 No
Washington 8 7 4 15 12 8 3 LLL Yes
Wisconsin 26 16 6 7 4 1 1 L No
West Virginia 7 5 2 1 L No
Wyoming 1 C Yes
Total 397 219 115 303 181 111 9 40 6 15


264 Public Choice (2020) 185:253–279
13
I wish certain things were different. For example, King et al. (2005) used the History of Women’s Suffrage, supplemented by states’ “Blue Books”, to track the language of the bills and whether they were voted on and whether, if so, they passed. When the information was available, the authors recorded the name of the bill’s proposer but never the party, and bill passage was coded as a binary 1–0, not as a roll-call vote total. Those are key pieces of information that I would have liked to know, both because I think that the partisanship of the proposer vis-à-vis the partisanship of the legislature can provide insights into how power promotes or suppresses reform efforts, and because I would have liked to know whether the vote tallies followed an almost disjoint process as elsewhere—with small levels of support morphing almost seamlessly into supermajority levels (an S-shape adoption curve, if you will). Such questions remain unresolved. Ultimately, I integrated something like studying relevant counterfactual moments in two ways. First, by carefully reading through and cleaning all the data on bill proposals in state houses, I became familiar with the within-state protocols. I thought long and hard about the proper unit of analysis. Scholars typically study legislative changes year-by-year or term-by-term. In a panel analysis of US state level reforms, each state and each year will be its own row of the data. What I realized, though, is that, oftentimes, the relevant legislative variables would not change across years (or we would not have measures of their changes) because legislatures do not turn over every year but do so typically biennially (state houses) or quadrennially (state senates). That institutional feature means that scholars adopting a fixed-effects framework on state level panel data might estimate correlations between competition and suffrage that were biased downward precisely because the competition variables changed less frequently than other variables. In other words, fixed effects regressions look for how changes within variables within states are related to changes in the dependent variable. If certain variables do not change within years coefficient sizes can be attenuated even though, in reality, whether the bill passes in the first year or the second of the legislative session may be less important than that it passed in a particular session. The worry also arises that off-the-shelf measures of competition are recorded at some point in the year that are not reflective of the actual composition of the legislature sitting when the bill was proposed. The lack of variation across years in legislative composition, and the potential for introducing post-treatment bias if the legislature’s composition was measured at the wrong point in time, caused a big headache. After taking a deep dive into various electoral histories to learn about when US legislatures turned over in the Nineteenth Century, I decided to use the legislative session as the unit of analysis. In addition, I decided to examine statistically the various stages of bill proposal and passage using a host of measures of the suffrage movement and about political competition. I discovered that bills were not more likely to be proposed in years when competition was more vigorous within states, but that the more competitive states considered more suffrage bills overall. Looking at changes in political competition surrounding bills on which votes were taken, I discovered that states that became more competitive in the legislative session during which a bill was voted on were more likely to pass the bill relative to states that voted on bills when competition was unchanged (some of this is detailed in Teele 2018a, Chap. 4). Finally, in what became the foundation of a stand-alone-article, I examined support for suffrage in state legislatures over time by focusing on all times during which suffrage bills passed (Teele 2018b). For the most part, the models I specified were not very sophisticated, but the innovations instead came from conceptualizing competition in a more comprehensive fashion. I found robust evidence for the notion that competition was linked to stronger support for suffrage, but that consolidated political power, whether in the form of longevity of the ruling party, the presence of political machines, and a larger than minimum winning coalition,


265
Public Choice (2020) 185:253–279
13
was associated with resistance to suffrage. Those relationships were, moreover, more profound in states where the suffrage movement was more active, providing some evidence that competition influenced the efficacy of the suffrage movement.
3 The fundamental problem of historical causal inference
Our studies of suffrage reforms highlight several difficulties for inferring causality in the study of specific historical events. The first, most straightforward, and ultimately most intractable simply is that the nature of the research questions makes it effectively impossible to generate new data that might meet the requirements of the potential-outcomes framework. That difficulty is compounded by what emerged as a central characteristic of the events in question, which occurred not as a single event, but as the culmination of a developing and sequential process. Finally, the existing research infrastructures on which we could rely as we assembled our empirical material and theorized our cases were of widely different quality, necessitating inevitable tradeoffs in the data that could be recovered or compiled and in the knowledge about cases that we could use to guide our scholarly resource allocations. The fundamental problem of causal inference as defined in the potential-outcomes framework is that we never can observe a causal effect directly, because only the outcome, and not both the outcome and potential outcome under a different treatment, is observable. Historical work throws up several obstacles to causal inference in this framework, but the basic difficulty is stated easily: historical analyses rely on data that necessarily are observational and usually post hoc. As a result, we are unable to rely on one of the most powerful means for causal identification—the deliberate randomization of exposure to treatment. Efforts to circumvent that difficulty in historical work have included the turn toward what is known as “design based inference”, that is, an intentional effort by the researcher to address the difficulties of causal analysis by their design choices rather than statistical modeling (Imbens 2010, p. 403; Keele 2015). Design-based approaches can include instrumental variable models, natural experiments (Dunning 2012), the use of directed acyclic graphs to facilitate conditioning for so-called collider variables (S. L. Morgan and Winship 2007; Pearl 1995), regression discontinuity designs, difference-in-difference models, as well as efforts to establish hypothesized causal relations empirically using contemporaneously generated data, for example, by conducting an experiment to establish individual-level mechanisms. Design-based approaches are extremely powerful tools, and already have done much to advance historical research. But as we suggested in the introduction, their utility is not distributed equally across different types of historical questions. Empirical historical research typically falls into one of three types: the study of legacies of historical processes; the use of “history as data” to test general theories; and the study of specific historical events, such
as the adoption of important political reforms or the occurrence of revolution.6 Table 2 outlines those approaches, including some examples, and indicates briefly the degree of compatibility with design-based inferential strategies for each category.
6 To be sure, the boundaries between the approaches are permeable. In many cases, as in the work of Weaver (2019) and Paglayan (2019), interest in a general theoretical question can lead to projects whose answers can emerge only from deep dives into historical records; the opposite also is true, as an interest in a specific event leads researchers to frame their projects as testing a more generalizable body of theory. We believe scholars can and should do more to usefully leverage the different advantages of each approach across their research projects. For example, those who seek to explain a single event rarely present so idiosyncratic a story that no generalizable mechanisms could not usefully be substantiated with contemporary data or newly designed experiments.


266 Public Choice (2020) 185:253–279
13
Table 2 Typology of approaches to studying history and the applicability of design-based research
Type of historical research Examples Efficacy of design-based inference
Historical legacies Acemoglu et al. (2001), Voigtländer and Voth (2012), Nunn (2008),
Acharya, Blackwell and Sen (2018), Abramson and Carter
(2016), Gaikwad (2015)
Often highly compatible, but difficulty identifying mechanisms
empirically
History-as-data Eggers and Spirling (2017), Cirone and Van Coppenolle (2018,
2019), Cox et al. (2016), Suryanarayan and White (2019), Weaver
(2019), Paglayan (2019)
Compatible when data are known to exist in appropriate form or
when paired with newly generated data
Causes of particular/major events Bateman (2018, 2019), Teele (2018a, b), Kreuzer (2010) Boix
(1999, 2010), Ahmed (2010), Kuo (2018), Jusko (2017), White
(2019)
Least compatible, especially when data are sparse/uneven and histo
riography is underdeveloped


267
Public Choice (2020) 185:253–279
13
Studies attempting to explain contemporary cross-sectional phenomenon as the legacy of long-term processes, as well as those using history as a source of data to examine general theories, are perhaps especially compatible with the assumptions and requirements of designbased approaches. If plausible instruments can be identified for a particular historical phenomenon, or if its occurrence produced discontinuities plausibly unrelated to other factors, then the statistical modeling of a long-term historical legacy can be relatively straightforward, with the identifying assumptions defended by descriptive analyses as well as qualita
tive process-tracing.7 History-as-data, by contrast, often begins from the fact that a researcher has located data or observed some discontinuity or as-if random assignment that pertains to a specific theoretical question and thereby facilitates causal identification. Exploiting such an opportunity could entail little more than an effort to expand the number of observations by extending a contemporary dataset backwards, but also more deliberate efforts to match the implications of theory with conditions or phenomena that are pertinent, but either unobserved or more difficult to study in the contemporary period. While such research often can assume that causal relationships are stable across different temporal periods, thereby ignoring potential changes in key parameters or assumptions undergirding any particular relationship, that assumption is not an intrinsic feature of the approach. In fact, much of the best research in that vein is attuned explicitly to the question whether theoretical foundations that have an established basis in one period apply in another, and often engages in an effort to demonstrate carefully when and where such relationships emerged (Carson and Sievert 2018). The findings from earlier historical periods can in turn provoke a valuable refinement of theory. By contrast, questions about the different causes of specific historical events—involving outcomes that are case-specific and already have happened (Mahoney et al. 2009; Roberts 1996)—may be the least well suited for design-based approaches. While major events generally have long-term legacies, and their occurrence may provide some insight into generalizable theories of politics, the emphasis in this line of research remains at least as much on understanding the particularities of a specific “case”—why it happened in the way and at the time it did—as on the universe of cases to which a hypothesized theory might apply. The foregoing has important implications for our ability to acquire the data that we might want or to rely on the guidance of theory developed with reference to contemporary phenomena. While the researcher can and should draw on generalized theories, their applicability or weight in the particular instance of interest needs to be demonstrated rather than assumed; that very particularity is in turn likely to limit the types of data that the researcher will be able to bring to bear in drawing causal inferences. For instance, it is not usually the case that the limits of historical data can be overcome by the addition of newly generated data that are deliberately structured to better satisfy the standards required of design-based inference. Insofar as the particular events or processes in which we are interested do not have the benefit of an already established and systematically organized infrastructure of data and knowledge—for example, careful empirical work measuring and describing par
ticular aspects of historical phenomena8—our research designs will face hard constraints in the types of data and assumptions that they realistically can hope to leverage. And when such an infrastructure exists, as it often does in well-plumbed research areas, then the
7 As Kocher and Monteiro (2016) have noted, the historical work necessary to justify the identifying assumptions is at least as important to generating confidence in the analysis as any of the actual modeling decisions. Historically oriented scholars who stumble on a potential instrument still have to undertake an extensive engagement with relevant historical work and possibly even their own qualitative process-tracing.
8 See, for example, the discussion of the work on English medieval villages in Carus and Ogilvie (2009).


268 Public Choice (2020) 185:253–279
13
likelihood of recovering new data that have not already contributed to the formulation of various theories in the literature, and therefore could serve as the basis for testing these
existing theories, is likely to be slim.9 The researcher then will be required to engage in explicit modeling of an iterative research process, such that the conditional probabilities of competing established theories being correct is evaluated by, for example, undertaking a Bayesian “dialogue with the data” (Fairfield and Charman 2019). As we saw in the vignettes above, intrinsic data limitations intersect with a more fundamental issue, which is how we conceptualize the relevant outcome in this type of analysis. As Pierson (2004) and others have stressed, many of the major historical events in which we are likely to be interested are better thought of not as events but as processes that unfold in historical time. Following Pierson (2004) and Blackwell (2013), we define a dynamic causal process as one in which the relevant actions or variables that influence an outcome of interest do not occur just once but as part of an unfolding sequence, in which the order in which variables appear or take on certain values matters, and the relationship between variables at one moment in time will alter their relationship, and their effect on the outcome, at subsequent moments. Such processes pose considerable difficulties for causal inference, regardless of whether the mode of inquiry is statistical, qualitative process-tracing, or a mix of different methodologies (Blackwell 2013). Since sequencing often is key for understanding historical events, analysis of event snapshots often will be hard pressed to satisfy the basic assumptions necessary for causal identification. More generally, whether a study relies primarily on qualitative or quantitative modes of evidence, the arbitrary temporal bounding of dynamic processes is likely to result in the misestimation of any particular causal effect as well as the relative importance of different hypothesized causes. Consider the two ways that historical events tend to be modeled in a statistical framework, both of which treat the occurrences in question as “single-shot” events. The first is to collect panel data for specific observational units (legislatures, countries, organizations) and to measure a host of variables at proximate intervals. In fixed-effects regressions, each observational unit’s values in a given time period are compared to average values that variable takes in other time periods, the “within” estimator. Fixed effects regressions cannot estimate coefficients for time-invariant variables (because the matrix cannot be inverted). Thus, the inferential leap is made on the basis of relative changes in independent variables over time (a flow), rather than the stocks of those variables. Historical event studies, on the other hand, assign independent weight to the passage of time (where the temporal relationship can be modeled in various ways), and can integrate both time invariant (stock) and time-varying (flow) variables (Box-Steffensmeier and Jones 1997, p. 1440). But a huge potential problem is that the time-varying covariates themselves are endogenous to the dependent variable. If previous debates about public policies affect political competition, for example, then competition is not exogenous to the outcome of interest. Hence, a cross-sectional or event history analyses of an occurrence at the moment of outcome, i.e., passage of reform, will show posttreatment bias in the estimated coefficients insofar as the values taken by key variables will be a function of their earlier exposure to other variables of interest.
9 As Ragin (2004, p. 126) notes with respect to the “well-reasoned” argument that new or refined theories can be tested only on newly collected data, such a conclusion effectively “puts an end to most case-oriented research” when “the number of relevant cases is limited by the historical record to a mere handful” (Ragin 2004, p. 126).


269
Public Choice (2020) 185:253–279
13
A similar problem confronts qualitative historical researchers. Consider some of the different tests used in process-tracing, the “hoop test”, “smoking-gun” test, or the promising exercise in Bayesian probability as “extended logic” outlined in Fairfield and Charman (2019). A hoop test simply proposes that “a given piece of evidence from within a case should be present for a hypothesis to be true”, and while it is seen as a necessary condition for establishing the validity of a given hypothesis, it also is an insufficient one (Mahoney 2015, p. 207; Bennett 2008). A smoking-gun test, by contrast, asks whether evidence exists of a condition for which the cause or outcome in question is necessary; passing such a test is sufficient, but not necessary to establishing the validity of a given hypothesis (Mahoney
2012, pp. 574–578).10 In each case, the validity of a hypothesis is established at a particular moment using the totality of available evidence. But as with “single-shot” statistical analyses, the arbitrary temporal bounding of the event fundamentally will alter the types of data that are available, as well as the estimated or assessed importance of different factors at the particular moment of their occurrence. If social-movement organizing is relatively muted at the end moment of reform, for example, it might be interpreted as failure to pass a hoop test, despite earlier having played a role in creating the more favorable public opinion that was essential to passage. Smoking-gun evidence for a hypothesis might equally be lacking at the moment of reform, even though it might have mattered both directly and indirectly through its effects on other variables earlier in the process. In one sense, the difficulties of modeling dynamic causal processes can be generalized to any process in which an action or treatment occurs not in a singular instance, but over time and in relation to other variables of interest. It follows that research into contemporary phenomena likewise should be “historical”, in the sense of attending to how a particular causal relationship developed over a defined sequence of time. Some degree of processtracing therefore will be essential for the study of processes even in the very recent past, even if it simply is intended to establish the plausibility of a particular modeling of a causal process. If data are sufficiently rich, or if new data directly tailored to the problem at hand can be generated (such as if the process in question is ongoing or recurring regularly), then those data can form the basis for statistical analyses that have been designed with dynamic causal processes in mind (Blackwell 2013). Such approaches, however, generally rely on a large amount of fine-grained and temporally comprehensive data, necessary if the researcher is going to estimate an integrated model that not only takes time into account but allows for development in the variables of interest (see also Wawro and Katznelson 2014). Making dynamic analysis central to research design intrinsically is more difficult for historical researchers because of our inevitable reliance on observational data in whose production we have had no say. In general, historical data coverage of complex and dynamic processes is uneven at best, and it is not uncommon to be forced to rely on indicators separated from the relevant events by several years or even decades. Unless the researcher is especially fortunate, the likelihood of having updated quantitative or even archival evidence at each relevant stage in the process is slim. Even when data do exist or could be recovered, the descriptive inferences we can make from them are not always clear, especially if they rest on assumptions or empirical relationships that hold in the contemporary
10 In the first test, the researcher asks whether all conditions defined by a particular hypothesis as necessary for an outcome’s occurrence are observable in the historical record, or whether the “auxiliary traces” of a theoretically relevant latent concept are present. In the second test, the researcher asks whether a given hypothesis being true is a necessary condition for the presence of a particular phenomenon in the historical record.


270 Public Choice (2020) 185:253–279
13
period, but not in an earlier one.11 The result is that we cannot reliably assume the existence of relevant data in sufficient quantities or detail to meet the requirements of a dynamic causal-inference strategy, and might not be able to infer a stable meaning to them even if they were available. A design-based approach to studying causality, for instance, would require us to take account of the unfolding and dynamic character of the process, but at the outset of a research project we often will lack the necessary data for doing so. Moreover, we lack methodological guidance for how and whether we need to accommodate the possibility that certain relevant variables act as “stocks” of previous rounds of play and not merely as “flows” relevant only at the moment of reform. Given that data from the past are sparse and uneven across time, dynamic causal processes are not something that reliably can be modeled in a statistical framework in much historical work.
4 The timeline of relevant counterfactuals
Given the difficulties intrinsic in drawing causal inferences from cases of dynamic causal processes, we believe that researchers would benefit from the formulation of a set of procedures that can facilitate the recognition of such dynamics and the application, upon an evaluation of the likely data sources and limitations, of appropriate methods. The inevitable variation in the quality and coarseness of data, whether amenable to quantification or not, means that no mechanical solution can be applied generally. Rather, what we suggest are a set of procedures intended to facilitate the empirical substantiation of causal arguments in cases of possible dynamic causal processes. Our solution to the problem of studying dynamic processes that lead to major historical events requires thinking big and thinking small. Large-N researchers want to increase the number of cases they study to be able to describe patterns and ultimately to infer causal relationships over a large domain, be it spatial, temporal, or both. Small-N researchers want to burrow into the details of the cases to gain a rich understanding of the facts on the ground, that is, to be able to make more specific claims about causal relationships. Although some scholars have suggested that the ontological orientations of researchers working in each of those modes may be different (Goertz and Mahoney 2012), we argue
11 That is partly why Robert Vitalis (2006) argues that “the past is another country”. Just as we expect students of comparative politics to develop competence in the requisite language and methodological tools necessary for fieldwork or engagement with a particular site, historical researchers must go to the archives and, just as critically, develop more than a passing familiarity with the relevant historical work on the period. In short, they must pay as close attention as historians do to the process by which their data were generated and to how its potential meaning might be altered by its historical specificity. For example, it is a safe assumption that most contemporary members of Congress desire reelection, and so information about retirement rates can be leveraged to tell us something about the competitive environment or voting records about constituency interests. It is not obvious that the same assumption should travel to the early Republic, and it only has been through high-quality historical work that have we been able to identify the timing and conditions of the emergence of an electoral connection and a more careerist posture toward elected office (Carson and Sievert 2018; Carson and Engstrom 2005). Similar discrepancies exist regarding the very basic act of voting, which looks nothing today like what it did in the nineteenth century, suggesting the real possibility that the types of information data on voting conveys do not translate easily between the two eras (Bensel 2004). A similar argument has been made for the studies of presidential vetoes, which changed with contextual shifts in the electorate that altered the veto’s audience and, thus, the incentives and meaning of doing so (McCarty 2009).


271
Public Choice (2020) 185:253–279
13
that it is possible to design a strategy for one’s research agenda that does both, and that such a design is crucial for studying major historical events quantitatively. Specifically, we propose that the first step for researchers interested in understanding major historical events is to construct a complete timeline of relevant counterfactual nodes for each observational unit, and then analyze the relationships between key theory-justified independent variables and the outcome (some failed and some successful) at each of the nodes. A basic bias in studying historical events is that our interest intrinsically is backward-looking—we know the outcome, and usually are looking for antecedent causeswhile it long has been recognized as a matter of historical practice that inquiry should “read history forward to reduce hindsight bias and conceptual reification” (Kreuzer 2019, p. 127; Ahmed 2010; Skinner 1969). What we propose is that the researcher begin with a backward-looking construction of the sequence that plausibly led to an ultimate outcome, and use that timeline to structure a forward-looking narrative or sequenced analysis culminating in the occurrence or event of interest. Starting with a timeline of potential counterfactuals entails re-conceptualizing the outcome not as a predetermined event, but as the product of a temporally developing set of factors, drawing out moments when the outcome plausibly could have occurred but did not. Constructing such a timeline will require us to recreate the sequence of events as it unfolded on the ground, in the service of eventually being able to evaluate the relative importance of different factors at different stages. Doing so often will mean going to primary source documents, like minutes of national legislatures or “blue books” for US state legislatures, or even to writings of political theorists, to create a literal timeline demarcating all of the years or legislative sessions when a given change was plausible. That research will in turn establish “nodes” in the history of an event in which the change could have occurred, providing information about relevant counterfactuals moments (Simon 2014). The counterfactual nodes are conceptualized in two distinct ways: as alternative outcomes in which the hypothesized causal and conditioning factors might have taken on distinct values—the standard basis for comparative analyses—but also as sequentially and developmentally linked moments, in which later nodes are likely to have developed out of earlier ones. With such a timeline in hand, the researcher can then walk forward through the process, evaluating the strengths of different hypotheses at sequential moments using the available or recoverable data and most-appropriate inferential approaches. That step can involve statistical analyses, hoop tests, smoking-gun tests, or qualitatively “inhabiting the world of each hypothesis” and assigning probabilities to the truth values of empirical propositions conditional on those hypotheses and our background knowledge (Fairfield and Charman 2017, p. 369). At each moment, we rely on the available empirical evidence and logical evaluation to assess not whether an event did or did not happen in a particular year, but rather why, in a year in which it might plausibly have happened, it did or did not. Given the inevitable unevenness in the data, the researcher’s evaluation of the hypothesized relationships at any particular node likely will be descriptive; but if rigorously and explicitly connected to theory, the researcher will be in a better position to make an inferential argument that rests not on any particular moment but across the totality of the causal sequence. The timeline of relevant counterfactual nodes serves several inferential functions. The first and most important is that it will guide deeper probing into archival and secondary sources to learn about the patterns of conflict and the nature of public and political discussions in the relevant moments. Qualitative understanding of the politics surrounding the nodes of potential reform will help researchers to generate “causal process observations”—observations about the actual political dynamics in the moments when reforms


272 Public Choice (2020) 185:253–279
13
were debated (Haggard and Kaufman 2012)—with the goal of abstracting away from the particular case at hand to formulate more general hypotheses. If one is interested not only in explaining a single historical event, but how similar events unfolded in other contexts (or cases), the timeline is further crucial for helping to establish which potential comparative cases are temporally analytically equivalent (Falleti 2013, p. 141). Finally, the timelines of relevant counterfactual nodes facilitate statistical inference. When we have a sense of the periods in which an outcome was possible, we can begin collecting data with an eye toward an empirical examination of the relationship between the outcome and key independent variables in those moments. We discuss each of those issues in turn.
4.1 Qualitative insights from studying counterfactual nodes
The first inferential function of constructing the timeline of relevant counterfactuals for each observational unit is qualitative. Researchers interested in historical events quickly will discover and come to know the existing research infrastructure on their topic—the amount, type and quality of the data that already has been produced by long-standing communities of scholars. While such infrastructures inevitably are of varying quality, their existence will be invaluable to any historically oriented social scientist, especially one studying dynamic historical processes. When the infrastructure is sparse, the researcher’s main contribution might be to help construct it, a task that “requires sleuthing, language proficiency, familiarity with the organization of archives, knowledge about legal restrictions guiding their access, intuitions of what might have been deliberately omitted or destroyed, and above all, persistence” (Kreuzer 2019, p. 125). Still, the unearthing of new facts and their inclusion in a coherent temporal sequence will build on the existing infrastructure. In the case of legislative reforms, for example, knowing when bills were debated and voted on provides a window for looking into newspaper archives, for delving into the personal correspondence of movement leaders and legislators; it also provides a framing for reading parliamentary minutes. The relevant dates also can help guide more selective searches into secondary historical literatures, as historians often will mention such things as asides in projects unrelated to our interests. Pinpointing the nodes of potential reform and gaining substantial familiarly with the primary and secondary source materials surrounding those nodes becomes the crucial material on which we draw context-based causal inferences about specific historical events. From such fine-grained knowledge we can then begin to telescope back to more abstract thinking about historical events. That is, we can begin to create more generalized hypotheses about the way the reform unfolded across time and space. How we configure temporal and geographic variation across our timeline will shape the types of comparisons we make (Kreuzer 2019, p. 128), whether between temporally sequenced events or between spatially separate events treated as occurring simultaneously, as well as our allocation of resources. It often will be infeasible to generate causal-process observations for every node on the timeline for all observational units. But consider again our running example of electoral reform: because of the way that reforms generally unfold in a legislative setting, studying the complete timeline of counterfactual nodes within a specific observational unit—for example, the occasions on which a specific state debated a proposal—generally will provide variation along key dimensions of the dependent, treatment and conditioning variables. That is true even for those units not ultimately adopting a reform, because most parliamentary systems require electoral change to gain support at


273
Public Choice (2020) 185:253–279
13
several different institutional levels before its adoption.12 Importantly, too, it is not necessarily true that the only positive case temporally is the last one. Sometimes particular parties are in favor of reform and are able to secure majorities in certain chambers when they are in power, but not when they are out of power. Hence, examining the complete timeline of counterfactual nodes within an observational unit is apt to produce insights about both why reforms gained support and why they failed within that case. In addition, as many comparative politics scholars have argued, understanding how reforms unfold over time—both in terms of the historical epoch and the sequencing of changes—is crucial for determining whether different cases are analytically similar to one another. It is only within the context of analytical similarly (or even more strongly “temporal unit homogeneity”) that qualitative inferences can be made about the underlying causes of the reform or the results thereof. A key agenda in the institutionalism literature has been related to understanding whether, for example, policy feedback loops or ratcheting effects are related to the temporal space in which change took place. Hence, for thinking about how things like duration, tempo, and acceleration matter for an event’s occurrence, establishing the timeline of relevant counterfactuals is a prerequisite (Grzymala-Busse 2010; Falleti 2013).
4.2 Statistical insights from studying relevant counterfactuals
At least two ways of working through the timeline of relevant counterfactual moments will help researchers engage in statistical inferences about causation. The first is that, as Kocher and Monteiro (2016) argue, design-based inference generally proceeds by arguing that some, if not all, key causal variables of interest were allocated in an as-if random way. Because the plausibility of those claims rests primarily on idiographic, qualitative knowledge, the intimate understanding of specific counterfactual episodes that emerge from constructing the timeline will help the researcher learn of opportunities for exploiting a designbased framework and explore whether the assumptions of the statistical model potentially are realized or excluded in studying a particular process. Second, identifying potential moments of reform and exploring the relationships between possibly key causal variables will allow researchers to assess whether the statistical relationship between the events is the same over time, or whether it changes in particular directions. Of course, in the process of generating a timeline of relevant counterfactuals, one will be able to identify existing data or opportunities for reducing archival or other qualitative data to quantitative form; ideally, the data that are produced will be of sufficiently high quality and granularity that existing statistical causal inference approaches to dynamic causal processes can be used. Such successful outcomes often will be unlikely, though. In that case, researchers might instead track an association between different variables over time, evaluating both statistically and from qualitative and primary sources whether and how their relationship might be evolving dynamically. The cost of doing so is that we will no longer be able to generate a single causal estimand. And the need to track a case temporally greatly will limit our degrees of freedom, often making a fully specified model even more infeasible than usual.
12 For example, upper chambers have to pass the law, referendums often are required, and presidents or governors might veto. Lower chambers can vote yes, but the reform nevertheless may stall. In many American states, suffrage extensions required a constitutional amendment, which often needed to be passed by two successive legislatures and then sent to the public for ratification.


274 Public Choice (2020) 185:253–279
13
But estimating a causal effect in a fully identified statistical model in is not the only way we judge cause-and-effect; by tracing the development of a causal process across many different types of data—a form of triangulation, for instance (Rothbauer 2008)—and connecting the unfolding process to a set of theoretically structured hypotheses, we might be able to make a persuasive case about the relative weights of different factors at different times—a causal interpretation (Griffin 1993)—even if we cannot say we have identified or estimated a single causal effect. Such an approach does not by any means resolve all the difficulties of causal inference in historical research. In fact, it only opens up new problems that largely have been neglected in the elaboration of the potential-outcomes framework. We see our proposed procedure as a first step in generating the relevant evidence, the equivalent of compiling and ordering the facts from a complex investigation. It represents a separate and analytically distinct task from constructing the logical argument and narrative that ultimately will connect them together. The appropriate standards by which such an overarching causal interpretation should be evaluated, however, are less clear, and we do not offer any formula for aggregating evi
dence drawn from different counterfactual tests or descriptive analyses.13 For the moment, at least, the absence of a single framework for aggregating distinct types of qualitative and statistical evidence across dynamic causal processes means that structured narrative accounts will remain an essential analytical tool for much causally oriented historical research. That is, the use of narratives in political science research should be tailored not
only for coherently presenting the argument and data,14 but for reconstructing the causal process for readers and allowing them to evaluate whether the researcher consistently has applied an explicitly stated logic of causal inference. The continuing analytical relevance of narrative history, therefore, is not only that it allows the writer to present an unfolding synthesis of structure and agency (Abrams 1980), but in how it facilitates the documentation and evaluation of changing causal relationships over time.
5 Toward a developmental perspective on causality
A growing body of scholarship in American political development and comparative politics uses quantitative tools to study the long-term persistence of institutions, to intervene in historiographical debates about the causes of major institutional transformations, and to draw on historical data for substantiating more generalized theories. The development of design-based inferential tools has greatly encouraged this “historical turn”, and enriched out understanding of the past and its enduring impact. We have argued, however, that the ease with which historically oriented social scientists will be able to draw upon these techniques will vary considerably with the type of
13 Scholars have developed promising avenues for disciplined evaluations of qualitative findings (Fairfield and Charman 2019), as well as case-selection strategies (Plümper et al. 2019), within or at least compatible with a potential-outcomes framework. While it is possible that those and other frameworks could be adapted for the task of aggregating evidence from sequential counterfactual tests, we suggest that it is an area where considerable work remains to be done.
14 Narratives aimed at a causal interpretation should, we argue, be as explicit and deliberate as possible in explaining the ordering, drawing the connections between them, and justifying the focus of the content relative to other possibilities so as to generate a constrained evaluation of counterfactual alternatives (Griffin 1993; Hawthorn 1991; Kelemen and Capoccia 2007; Weber 1949).


275
Public Choice (2020) 185:253–279
13
causal relationship they are studying. Historical events characterized by dynamic processes pose obstacles to causal inference that are especially challenging in this framework, both because of the intrinsic difficulties of estimating a non-biased effect in these cases (Blackwell 2013; Pierson 2004), but also because the data is unlikely to be of a quality or quantity necessary for conducting an integrated empirical analysis. Our standard methodological toolkit, including historical event analysis, fixed effects regression frameworks, as well as many of the logical tests essential for evaluating qualitative studies, are likely to produce biased estimates and lead to specious conclusions if they fail to model a historical process’s dynamic character. But the nature and quality of much historical data usually will not be up to the challenge of doing so. As a consequence, some of the other tasks of social scientific inquiry rightfully might take a more prominent place in the study of historical events, such as the empirical description of what happened or the interpretative effort to reconstruct the meaning it held for participants and subsequent observers. While most of us aspire to making causal claims, we should be aware of the collective costs to the discipline that follow from prioritizing causal identification over other forms of knowledge production. Without descriptive work, or with shoddy and incomplete descriptive work uninterrogated by a broader scholarly community, our hopes of identifying causal relationships will be illusory. The contribution that a particular body of research makes to knowledge should be measured not by whether a research project identifies a causal relationship, but by whether it materially advances our understanding of a particular question or research area. We should not, however, abandon altogether the hope of making causal claims about historical events. Statistical estimation of a causal effect is not the only means by which causal inference can be undertaken—given sufficiently specified theory, description itself arguably is a powerful tool for establishing causality (Falleti 2016). In addition, the potential outcomes framework outlines a logic of inference, on the basis of which a set of methodological approaches and accompanying conditions and assumptions have been elaborated. We believe that this logic can and ought to guide our research even if the methodological conditions have not been met; and we encourage researchers to continue to work on topics that are theoretically interesting regardless of whether or not they have found some historical quirk that could plausibly result in an as-if random assignment to a treatment and control condition. As we have argued, putting the logic of the potential outcomes framework into practice requires us to elaborate not only a methodological toolkit appropriate for different circumstances, but a set of procedures that can be used to determine what type of causal process we are dealing with and what types of evidence might exist or be recovered at different stages of an unfolding process. We have suggested that one such procedure should be the construction of timelines of relevant counterfactual moments, with the dual purpose of helping researchers model a dynamic causal process and facilitating decisions about how to allocate sparse research time. One advantage of this procedure is that it provides a bridge between historical institutionalists and the growing number of scholars interested in applying design-based inferential strategies to historical questions. Constructing the timeline requires researchers to detail the evidence that exists for the different stages of the process, and to evaluate the possible inferences that can be made on this basis about any particular stage or the larger sequence. But the process of doing so embodies some of the orienting methodological practices already common to many students of American political development and historical institutionalism: (1) Sequence and timing matter, and when an action occurs can be as important as if it occurred (Pierson 2004). (2) The relationships between variables and


276 Public Choice (2020) 185:253–279
13
processes of interest may differ across distinct temporal periods (Wawro and Katznelson 2014). (3) Finally, the configuration of variables that might be observable at the moment of an event’s “occurrence” does not always provide an adequate explanation of their relative contributions over time. A developmental perspective to causality requires us to ask whether, to what extent, and to what consequence the events or processes in which we are interested are characterized by the three foregoing premises, and to plan our research strategies accordingly.
Acknowledgements We thank Tatiana Alfonso, Maria Paula Saffon, Boris Heersink, Didi Kuo, Alexandra Cirone, Michael Weaver, Agustina Paglayan, Jeff Jenkins, Nolan McCarty and Joshua Simon for their helpful comments.
References
Abrams, P. (1980). History, sociology, historical sociology. Past and Present, 87(1), 3–16. Abramson, S. F., & Carter, D. B. (2016). The historical origins of territorial disputes. American Political Science Review, 110(4), 675–698.
Acemoglu, D., Johnson, S., & Robinson, J. A. (2001). The colonial origins of comparative development: An empirical investigation. The American Economic Review, 91(5), 1369–1401.
Acharya, A., Blackwell, M., & Sen, M. (2018). Deep roots: How slavery still shapes southern politics. Princeton, NJ: Princeton University Press. Ahmed, A. (2010). Reading history forward: the origins of electoral systems in European democracies. Comparative Political Studies, 43(8–9), 1059–1088. Banaszak, L. A. (1996). Why movements succeed or fail: Opportunity, culture, and the struggle for woman suffrage. Princeton: Princeton University Press.
Bateman, D. A. (2018). Disenfranchising democracy: Constructing the electorate in the United States, the United Kingdom, and France. Cambridge: Cambridge University Press. Bateman, D. A. (2019). Partisan polarization on black suffrage, 1785–1868. Perspectives on Politics. https:// doi.org/10.1017/S1537592719001087. Bateman, D. A., Katznelson, I., & Lapinski, J. S. (2018). Southern nation: Congress and white supremacy after reconstruction. Princeton, NJ: Princeton University Press. Bennett, A. (2008). Process tracing: A bayesian perspective. In J. M. Box-Steffensmeier, H. E. Brady, & D. Collier (Eds.), The Oxford handbook of political methodology (pp. 217–270). Oxford: Oxford University Press.
Bensel, R. F. (2004). The American ballot box in the mid-nineteenth century. Cambridge: Cambridge University Press. Blackwell, M. (2013). A framework for dynamic causal inference in political science. American Journal of Political Science, 57(2), 504–520.
Boix, C. (1999). Setting the rules of the game: The choice of electoral systems in advanced democracies. American Political Science Review, 93(3), 609–624.
Boix, C. (2010). Electoral markets, party strategies, and proportional representation. American Political Science Review, 104(2), 404–413.
Box-Steffensmeier, J. M., & Jones, B. S. (1997). Time is of the essence: Event history models in political science. American Journal of Political Science, 41(4), 1414–1461.
Capoccia, G., & Ziblatt, D. (2010). The historical turn in democratization studies: A new research agenda for Europe and beyond. Comparative Political Studies, 43(8–9), 931–968. Carson, J. L., & Engstrom, E. J. (2005). Assessing the electoral connection: Evidence from the early United States. American Journal of Political Science, 49(4), 746–757.
Carson, J. L., & Sievert, J. (2018). Electoral incentives in Congress. Ann Arbor, MI: University of Michigan Press. Carus, A. W., & Ogilvie, S. (2009). Turning qualitative into quantitative evidence: A well-used method made explicit. The Economic History Review, 62(4), 893–925. Catt, C. C., & Shuler, N. R. (1923). Woman suffrage and politics: The inner story of the suffrage movement. New York: Charles Scribner’s Sons.


277
Public Choice (2020) 185:253–279
13
Cirone, A., & Van Coppenolle, B. (2018). Cabinets, committees, and careers: The causal effect of committee service. The Journal of Politics, 80(3), 948–963.
Cirone, A., & Van Coppenolle, B. (2019). Bridging the gap: Lottery-based procedures in early parliamentarization. World Politics, 71(2), 197–235. Cox, L., & Cox, J. H. (1967). Negro suffrage and Republican politics: The problem of motivation in reconstruction historiography. The Journal of Southern History, 33(3), 303–330. Cox, G. W., Fiva, J. H., & Smith, D. M. (2016). The contraction effect: How proportional representation affects mobilization and turnout. The Journal of Politics, 78(4), 1249–1263. Deaton, A. (2010). Instruments, randomization, and learning about development. Journal of Economic Literature, 48(2), 424–455. Diamond, J., & Robinson, J. A. (2010). Natural experiments of history. Cambridge, MA: Harvard University Press.
Dunning, T. (2012). Natural experiments in the social sciences: A design-based approach. Cambridge: Cambridge University Press. Eggers, A. C., & Spirling, A. (2017). Incumbency effects and the strength of party preferences: Evidence from multiparty elections in the United Kingdom. The Journal of Politics, 79(3), 903–920. Fairfield, T., & Charman, A. E. (2017). Explicit Bayesian analysis for process tracing: Guidelines, opportunities, and caveats. Political Analysis, 25(3), 363–380. Fairfield, T., & Charman, A. (2019). A dialogue with the data: The Bayesian foundations of iterative research in qualitative social science. Perspectives on Politics, 17(1), 154–167. Falleti, T. G. (2013). Decentralization in time: a process-tracing approach to federal dynamics of change. In A. Benz & J. Broschek (Eds.), Federal dynamics: Continuity, change, and the varieties of federalism. New York: Oxford University Press. Falleti, T. G. (2016). Process tracing of extensive and intensive processes. New Political Economy, 21(5), 455–462.
Field, P. F. (1982). The politics of race in New York: The struggle for black suffrage in the civil war era. Ithaca, NY: Cornell University Press. Gaikwad, N. (2015). East India companies and long-term economic change in India. Presented at the International Political Economy Society. http://www.nikhargaikwad.com/Papers_files/Gaikwad_ EICs_2014.pdf. 1 August 2019.
Goertz, G., & Mahoney, J. (2012). A tale of two cultures: Qualitative and quantitative research in the social sciences. Princeton, NJ: Princeton University Press. Griffin, L. J. (1993). Narrative, event-structure analysis, and causal interpretation in historical sociology. American Journal of Sociology, 98(5), 1094–1133.
Grzymala-Busse, A. (2010). The best laid plans: The impact of informal rules on formal institutions in transitional regimes. Studies in Comparative International Development, 45(3), 311–333.
Haggard, S., & Kaufman, R. R. (2012). Inequality and regime change: Democratic transitions and the stability of democratic rule. American Political Science Review, 106(3), 495–516. Hawthorn, G. (1991). Plausible worlds: Possibility and understanding in history and the social sciences. Cambridge: Cambridge University Press. Haydu, J. (1998). Making use of the past: Time periods as cases to compare and as sequences of problem solving. American Journal of Sociology, 104(2), 339–371.
Heckman, J. J., & Urzúa, S. (2010). Comparing IV with structural models: what simple IV can and cannot identify. Journal of Econometrics, 156(1), 27–37.
Holland, P. W. (1986). Statistics and causal inference. Journal of the American Statistical Association, 81(396), 945–960. Imbens, G. W. (2010). Better LATE than nothing: Some comments on Deaton (2009) and Heckman and Urzua (2009). Journal of Economic Literature, 48(2), 399–423. Jusko, K. L. (2017). Who speaks for the poor? Electoral geography, party entry, and representation. Cambridge: Cambridge University Press. Keele, L. (2015). The statistics of causal inference: A view from political methodology. Political Analysis, 23(3), 313–335. Kelemen, R. D., & Capoccia, G. (2007). The study of critical junctures: Theory, narrative, and counterfactuals in historical institutionalism. World Politics, 59(3), 341–369. King, B. G., Cornwall, M., & Dahlin, E. C. (2005). Winning woman suffrage one step at a time: Social movements and the logic of the legislative process. Social Forces, 83(3), 1211–1234. Kocher, M. A., & Monteiro, N. P. (2016). Lines of demarcation: causation, design-based inference, and historical research. Perspectives on Politics, 14(4), 952–975. Kreuzer, M. (2010). Historical knowledge and quantitative analysis: The case of the origins of proportional representation. American Political Science Review, 104(2), 369–392.


278 Public Choice (2020) 185:253–279
13
Kreuzer, M. (2019). The structure of description: Evaluating descriptive inferences and conceptualizations. Perspectives on Politics, 17(1), 122–139. Kuo, D. (2018). Clientelism, capitalism, and democracy: The rise of programmatic politics in the United States and Britain. Cambridge: Cambridge University Press. Mahoney, J. (2012). The logic of process tracing tests in the social sciences. Sociological Methods and Research, 41(4), 570–597.
Mahoney, J. (2015). Process tracing and historical explanation. Security Studies, 24(2), 200–218. Mahoney, J., Kimball, E., & Koivu, K. L. (2009). The logic of historical explanation in the social sciences. Comparative Political Studies, 42(1), 114–146.
McCammon, H. J., Campbell, K. E., Granberg, E. M., & Mowery, C. (2001). How movements win: Gendered opportunity structures and U.S. women’s suffrage movements, 1866 to 1919. American Sociological Review, 66(1), 49–70.
McCarty, N. (2009). Presidential vetoes in the early republic: Changing constitutional norms or electoral reform? The Journal of Politics, 71(2), 369–384.
Morgan, K. J. (2016). Comparative politics and American political development”. In R. M. Valelly, S. Mettler, & R. Lieberman (Eds.), The Oxford handbook of American political development. New York: Oxford University Press.
Morgan, S. L., & Winship, C. (2007). Counterfactuals and causal inference: Methods and principles for social research. New York: Cambridge University Press. Neyman, J. (1990). On the application of probability theory to agricultural experiments. Essay on principles. Section 9. Statistical Science, 5(4), 465–472. Nunn, N. (2008). The long-term effects of Africa’s slave trades. The Quarterly Journal of Economics, 123(1), 139–176. Paglayan, A. S. (2019). Public-sector unions and the size of government. American Journal of Political Science, 63(1), 21–36.
Pearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(1), 669–688. Pierson, P. (2004). Politics in time. Princeton, NJ: Princeton University Press. Plümper, T., Troeger, V. E., & Neumayer, E. (2019). Case selection and causal inferences in qualitative comparative research. PLoS ONE, 14(7), e0219727. Ragin, C. C. (2004). Turning the tables: How case-oriented research challenges variable-oriented research. In H. E. Brady & D. Collier (Eds.), Rethinking social inquiry (pp. 123–138). Lanham, MD: Rowman & Littlefield. Roberts, C. (1996). The logic of historical explanation. University Park, PA: Pennsylvania State University Press.
Rohlfing, I. (2012). Case studies and causal inference: An integrative framework. Basingstoke: Palgrave Macmillan.
Rothbauer, P. M. (2008). Triangulation. The SAGE encyclopedia of qualitative research methods (pp. 893–894). Thousand Oaks: SAGE Publications. Rubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology, 66(5), 688–701.
Sekhon, J. S., & Titiunik, R. (2012). When natural experiments are neither natural nor experiments. American Political Science Review, 106(1), 35–57.
Simon, J. (2014). The Americas’ more perfect unions: New institutional insights from comparative political theory. Perspectives on Politics, 12(4), 808–828.
Skinner, Q. (1969). Meaning and understanding in the history of ideas. History and Theory, 8(1), 3–53. Suryanarayan, P., & White, S. (2019). Slavery, reconstruction, and bureaucratic capacity in the American south. Available at SSRN: https://papers.ssrn.com/abstract=2951964. 14 January 2019. Teele, D. L. (2014). Ordinary democratization: the electoral strategy that won British women the vote. Politics and Society, 42(4), 537–561. Teele, D. L. (2018a). Forging the franchise: The political origins of the women’s vote. Princeton, NJ: Princeton University Press. Teele, D. L. (2018b). How the west was won: Competition, mobilization, and women’s enfranchisement in the United States. The Journal of Politics, 80(2), 442–461. Thelen, K. (1999). Historical institutionalism in comparative politics. Annual Review of Political Science, 2(1), 369–404.
Valelly, R. M. (2004). The two reconstructions: The Struggle for black enfranchisement. Chicago: University of Chicago Press. Vitalis, R. (2006). The past is another country. In E. Perecman & S. R. Curran (Eds.), A handbook for social science field research: Essays & bibliographic sources on research design and methods (pp. 1–17). Thousand Oaks, CA: SAGE.


279
Public Choice (2020) 185:253–279
13
Voigtländer, N., & Voth, H.-J. (2012). Persecution perpetuated: The medieval origins of anti-semitic violence in Nazi Germany. The Quarterly Journal of Economics, 127(3), 1339–1392. Wang, X. (1997). The trial of democracy: Black suffrage and northern Republicans, 1860–1910. Athens, GA: University of Georgia Press. Wawro, G. J., & Katznelson, I. (2014). Designing historical social scientific inquiry: How parameter heterogeneity can bridge the methodological divide between quantitative and qualitative approaches. American Journal of Political Science, 58(2), 526–546.
Weaver, M. (2019). ‘Judge lynch’ in the court of public opinion: Publicity and the de-legitimation of lynching. American Political Science Review, 113(2), 293–310.
Weber, M. (1949). The methodology of the social sciences. Glencoe, Il: Free Press. White, S. (2019). World War II and American racial politics. Cambridge: Cambridge University Press.
Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.


Reproduced with permission of copyright owner.
Further reproduction prohibited without permission.